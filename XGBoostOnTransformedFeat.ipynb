{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d19c3-62e6-43fd-b457-e0c023c2f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set pandas display option to show full column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Load and preprocess the training data\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('data/Train.csv')\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'], errors='coerce')\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "train_df = train_df.sort_values('Date')\n",
    "\n",
    "# Forward fill and backward fill NaN values\n",
    "train_df.fillna(method='ffill', inplace=True)\n",
    "train_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Drop any remaining NaN values\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "# Replace infinite values with NaN again\n",
    "train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Ensure 'GT_NO2' (target) has no NaNs\n",
    "train_df = train_df.dropna(subset=['GT_NO2'])\n",
    "\n",
    "# Define target variable and features to exclude\n",
    "target = 'GT_NO2'\n",
    "exclude_columns = ['ID_Zindi', 'Date', 'ID', target]\n",
    "\n",
    "# Get list of original features\n",
    "original_features = [col for col in train_df.columns if col not in exclude_columns]\n",
    "\n",
    "# Extract cyclical features from 'Date'\n",
    "train_df['day_of_year'] = train_df['Date'].dt.dayofyear\n",
    "train_df['day_sin'] = np.sin(2 * np.pi * train_df['day_of_year'] / 365.25)\n",
    "train_df['day_cos'] = np.cos(2 * np.pi * train_df['day_of_year'] / 365.25)\n",
    "\n",
    "# Add cyclical features to original features\n",
    "original_features.extend(['day_sin', 'day_cos'])\n",
    "\n",
    "# Define transformations\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def log_transform(x):\n",
    "    return np.log1p(x.clip(lower=0))\n",
    "\n",
    "def sqrt_transform(x):\n",
    "    return np.sqrt(x.clip(lower=0))\n",
    "\n",
    "def square_transform(x):\n",
    "    return np.square(x)\n",
    "\n",
    "def reciprocal_transform(x):\n",
    "    return 1 / (x + 1e-6)  # Add small constant to avoid division by zero\n",
    "\n",
    "transformations = [\n",
    "    ('identity', identity),\n",
    "    ('log', log_transform),\n",
    "    ('sqrt', sqrt_transform),\n",
    "    ('square', square_transform),\n",
    "    ('reciprocal', reciprocal_transform),\n",
    "]\n",
    "\n",
    "# Apply transformations to each feature in training data\n",
    "transformed_feature_names = []\n",
    "for feature in original_features:\n",
    "    for name, func in transformations:\n",
    "        transformed_feature_name = f\"{feature}_{name}\"\n",
    "        try:\n",
    "            transformed_values = func(train_df[feature])\n",
    "            if np.isfinite(transformed_values).all():\n",
    "                train_df[transformed_feature_name] = transformed_values\n",
    "                transformed_feature_names.append(transformed_feature_name)\n",
    "            else:\n",
    "                print(f\"Transformation {name} resulted in non-finite values for feature {feature}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not transform {feature} using {name}: {e}\")\n",
    "\n",
    "# Handle polynomial features (degree 2) including interactions\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_poly = poly.fit_transform(train_df[original_features])\n",
    "poly_feature_names = poly.get_feature_names_out(original_features)\n",
    "\n",
    "# Create DataFrame for polynomial features\n",
    "df_poly = pd.DataFrame(X_poly, columns=poly_feature_names)\n",
    "\n",
    "# Remove the original features to avoid duplication\n",
    "poly_feature_names = [name for name in poly_feature_names if name not in original_features]\n",
    "\n",
    "# Concatenate polynomial features with the DataFrame\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), df_poly[poly_feature_names].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Add polynomial feature names to transformed_feature_names\n",
    "transformed_feature_names.extend(poly_feature_names)\n",
    "\n",
    "# Prepare X and y\n",
    "X_train = train_df[transformed_feature_names]\n",
    "y_train = train_df[target]\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Remove columns with constant values\n",
    "X_train = X_train.loc[:, X_train.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Ensure that y aligns with X_train\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Feature selection using LassoCV\n",
    "lasso = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "coef = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "selected_features = coef[coef != 0].index.tolist()\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features using LassoCV\")\n",
    "\n",
    "# Prepare data with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "# Standardize selected features\n",
    "X_train_selected_scaled = scaler.fit_transform(X_train_selected)\n",
    "\n",
    "# Train the XGBoost model on the entire training set\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_selected_scaled, y_train)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Process the test data\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], errors='coerce')\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "test_df = test_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "test_df = test_df.sort_values('Date')\n",
    "\n",
    "# Forward fill and backward fill NaN values\n",
    "test_df.fillna(method='ffill', inplace=True)\n",
    "test_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Drop any remaining NaN values\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Replace infinite values with NaN again\n",
    "test_df = test_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Extract cyclical features from 'Date'\n",
    "test_df['day_of_year'] = test_df['Date'].dt.dayofyear\n",
    "test_df['day_sin'] = np.sin(2 * np.pi * test_df['day_of_year'] / 365.25)\n",
    "test_df['day_cos'] = np.cos(2 * np.pi * test_df['day_of_year'] / 365.25)\n",
    "\n",
    "# Apply the same transformations to test data\n",
    "for feature in original_features:\n",
    "    for name, func in transformations:\n",
    "        transformed_feature_name = f\"{feature}_{name}\"\n",
    "        if transformed_feature_name in selected_features:\n",
    "            try:\n",
    "                transformed_values = func(test_df[feature])\n",
    "                if np.isfinite(transformed_values).all():\n",
    "                    test_df[transformed_feature_name] = transformed_values\n",
    "                else:\n",
    "                    print(f\"Transformation {name} resulted in non-finite values for feature {feature}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not transform {feature} using {name}: {e}\")\n",
    "\n",
    "# Generate polynomial features for test data\n",
    "X_test_poly = poly.transform(test_df[original_features])\n",
    "df_test_poly = pd.DataFrame(X_test_poly, columns=poly.get_feature_names_out(original_features))\n",
    "\n",
    "# Concatenate polynomial features with the test DataFrame\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), df_test_poly[poly_feature_names].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Prepare test data with selected features\n",
    "X_test = test_df[selected_features]\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Remove columns with constant values (if any)\n",
    "X_test = X_test.loc[:, X_test.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Standardize features using the scaler fitted on training data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID_Zindi': test_df['ID_Zindi'],\n",
    "    'GT_NO2_Predicted': test_predictions\n",
    "})\n",
    "\n",
    "# Display the first few rows of the submission\n",
    "print(\"\\nPredictions on Test Data:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Optionally, save the predictions to a CSV file\n",
    "submission.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

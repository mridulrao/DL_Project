{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a492e1df-d21f-4a49-b2c6-4e0b8abffe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCombine Train & Test\\nSort the data - based on dates\\n\\nClustering Algo\\nGet the latitude and longitude - (stored in radian --needs to be converted)\\nApply clustering alogrithm -- create 3 clusters \\n\\nCreate 3 data splites - based on cluster ID \\n\\nNow processing for each data separately \\nFill the missing values \\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Combine Train & Test\n",
    "Sort the data - based on dates\n",
    "\n",
    "Clustering Algo\n",
    "Get the latitude and longitude - (stored in radian --needs to be converted)\n",
    "Apply clustering alogrithm -- create 3 clusters \n",
    "\n",
    "Create 3 data splites - based on cluster ID \n",
    "\n",
    "Now processing for each data separately \n",
    "Fill the missing values \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85c61210-79be-4044-8b06-6d6dc8c31975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29bf9a8b-e11b-4e54-b60b-2da0b0658246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1248/3701399781.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Combine Train and Test datasets\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Convert the 'Date' column to datetime format for sorting\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
    "\n",
    "# Sort the data based on dates\n",
    "combined_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Reset index after sorting\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "combined_df['LAT_rad'] = np.radians(combined_df['LAT'])\n",
    "combined_df['LON_rad'] = np.radians(combined_df['LON'])\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "combined_df['Cluster_ID'] = kmeans.fit_predict(combined_df[['LAT_rad', 'LON_rad']])\n",
    "\n",
    "# Split the data into three subsets based on the cluster IDs\n",
    "cluster_0_df = combined_df[combined_df['Cluster_ID'] == 0].copy()\n",
    "cluster_1_df = combined_df[combined_df['Cluster_ID'] == 1].copy()\n",
    "cluster_2_df = combined_df[combined_df['Cluster_ID'] == 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8648f2c6-fcd2-4a99-bece-324bc9b08aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18632, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_0_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af48d111-af53-49ab-a071-2abb63879623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52608, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b98ff2e7-5dd7-47cb-9594-9bdd6e8c14d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21920, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe30ad54-d5bf-47ea-96bb-374ad7900f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import splrep, splev\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        \n",
    "    def scale_and_interpolate(self, features):\n",
    "        for feature in features:\n",
    "            scaler = MinMaxScaler()\n",
    "            self.df[f'{feature}_scaled'] = scaler.fit_transform(self.df[[feature]])\n",
    "\n",
    "            mask_finite = np.isfinite(self.df[f'{feature}_scaled'].values)\n",
    "            known_indices = self.df.index.values[mask_finite]\n",
    "            known_values = self.df[f'{feature}_scaled'].values[mask_finite]\n",
    "            missing_indices = self.df.index.values[~mask_finite]\n",
    "\n",
    "            self.df[f'{feature}_bspline'] = self.df[f'{feature}_scaled']\n",
    "            tck = splrep(known_indices, known_values)\n",
    "            self.df.loc[~mask_finite, f'{feature}_bspline'] = splev(missing_indices, tck)\n",
    "            self.df[feature] = scaler.inverse_transform(self.df[[f'{feature}_bspline']])\n",
    "\n",
    "    def add_moving_stats(self, window_size, features):\n",
    "        for feature in features:\n",
    "            self.df[f'{feature}_ma_{window_size}'] = self.df[f'{feature}_bspline'].rolling(window=window_size).mean()\n",
    "            self.df[f'{feature}_std_{window_size}'] = self.df[f'{feature}_bspline'].rolling(window=window_size).std()\n",
    "\n",
    "    def add_monthly_averages(self, features):\n",
    "        self.df['Date'] = pd.to_datetime(self.df['Date'], errors='coerce', dayfirst=True)\n",
    "        self.df['month'] = self.df['Date'].dt.month\n",
    "        for feature in features:\n",
    "            monthly_avg = self.df.groupby('month')[f'{feature}_bspline'].mean()\n",
    "            self.df[f'monthly_avg_{feature}'] = self.df['month'].map(monthly_avg)\n",
    "\n",
    "    def add_seasonal_decomposition(self, features, periods):\n",
    "        for feature, period in zip(features, periods):\n",
    "            stl = STL(self.df[f'{feature}_bspline'], period=period)\n",
    "            result = stl.fit()\n",
    "            self.df[f'{feature}_trend'] = result.trend\n",
    "            self.df[f'{feature}_seasonal'] = result.seasonal\n",
    "            self.df[f'{feature}_residual'] = result.resid\n",
    "\n",
    "    def add_fourier_transform(self, periods, n_harmonics, columns):\n",
    "        for col, period, harmonics in zip(columns, periods, n_harmonics):\n",
    "            t = (self.df[col] - self.df[col].min()).dt.days.values if pd.api.types.is_datetime64_any_dtype(self.df[col]) else self.df[col].values\n",
    "            for k in range(1, harmonics + 1):\n",
    "                self.df[f'{col}_sin_{k}'] = np.sin(2 * np.pi * k * t / period)\n",
    "                self.df[f'{col}_cos_{k}'] = np.cos(2 * np.pi * k * t / period)\n",
    "\n",
    "    def transform(self, features, window_size, fourier_periods, fourier_harmonics, seasonal_periods):\n",
    "        self.scale_and_interpolate(features)\n",
    "        self.add_moving_stats(window_size, features)\n",
    "        self.add_monthly_averages(features)\n",
    "        self.add_seasonal_decomposition(features, seasonal_periods)\n",
    "        self.add_fourier_transform(fourier_periods, fourier_harmonics, features)\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "127c7cae-9c92-467a-a3bf-c26e579e2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LST', 'AAI', 'CloudFraction', 'NO2_strat', 'NO2_total', 'NO2_trop', 'TropopausePressure']\n",
    "transformer_df_cluster_0 = DataTransformer(cluster_0_df)\n",
    "transformed_df_cluster_0 = transformer_df_cluster_0.transform(\n",
    "    features=features, \n",
    "    window_size=7, \n",
    "    fourier_periods=[365.25, 182, 182, 91], \n",
    "    fourier_harmonics=[4, 3, 3, 3],\n",
    "    seasonal_periods=[365, 182, 182, 91]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8f7af40-8dcd-4918-8f67-a0eb13f99b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LST', 'AAI', 'CloudFraction', 'NO2_strat', 'NO2_total', 'NO2_trop', 'TropopausePressure']\n",
    "transformer_df_cluster_1 = DataTransformer(cluster_1_df)\n",
    "transformed_df_cluster_1 = transformer_df_cluster_1.transform(\n",
    "    features=features, \n",
    "    window_size=7, \n",
    "    fourier_periods=[365.25, 182, 182, 91], \n",
    "    fourier_harmonics=[4, 3, 3, 3],\n",
    "    seasonal_periods=[365, 182, 182, 91]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39101779-8936-466e-a022-2bdcc78c7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LST', 'AAI', 'CloudFraction', 'NO2_strat', 'NO2_total', 'NO2_trop', 'TropopausePressure']\n",
    "transformer_df_cluster_2 = DataTransformer(cluster_2_df)\n",
    "transformed_df_cluster_2 = transformer_df_cluster_2.transform(\n",
    "    features=features, \n",
    "    window_size=7, \n",
    "    fourier_periods=[365.25, 182, 182, 91], \n",
    "    fourier_harmonics=[4, 3, 3, 3],\n",
    "    seasonal_periods=[365, 182, 182, 91]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a45a4987-b0a9-41b3-b8b9-d0b54d70c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_combined_df = pd.concat([transformed_df_cluster_0, transformed_df_cluster_1, transformed_df_cluster_2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7319d47-ccf5-48b2-a308-9e09432a602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed_df = transformed_combined_df[transformed_combined_df['ID_Zindi'].isin(train_df['ID_Zindi'])].copy()\n",
    "test_transformed_df = transformed_combined_df[transformed_combined_df['ID_Zindi'].isin(test_df['ID_Zindi'])].copy()\n",
    "\n",
    "# Step 2: Reset index for each DataFrame if needed\n",
    "train_transformed_df.reset_index(drop=True, inplace=True)\n",
    "test_transformed_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e214bad6-29a8-4637-b573-9ac9ece5eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86584, 91)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0cd1eca-f8fc-4a0e-9c55-f77d2412ff46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6576, 91)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ce0a400-b889-440d-b96b-96a390f37f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed_df.to_csv(\"New_trans_train.csv\")\n",
    "test_transformed_df.to_csv(\"New_trans_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5449ccdd-326b-4dd0-aa9a-7cf6c6d441e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster_0_df = train_transformed_df[train_transformed_df['Cluster_ID'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be065953-9688-457a-9d82-d95e4eeab822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16440, 91)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cluster_0_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2597aa4-bc73-4782-a503-be37cbde31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster_0_df.to_csv(\"Cluster_0_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d645403-271f-4885-8a42-0dbc26140548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
